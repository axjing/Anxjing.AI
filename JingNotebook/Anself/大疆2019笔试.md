### 大疆DJI2019届秋季招聘笔试：
机器学习算法工程师2018年07月09日 链接：https://www.nowcoder.com/discuss/85562
关于大疆机器学习岗位的笔试题B卷（分两次考试：A卷和B卷）
## 单选题
1. 关于Logistic回归和SVM，以下说法错误的是？
Logistic回归可用于预测事件发生概率的大小
Logistic回归的目标函数是最小化后验概率  <font face="黑体" color=green size=4>(1)</font>
SVM的目标的结构风险最小化
SVM可以有效避免模型过拟合
2. 假设三个稠密矩阵（Dense Matrix）A, B, C的尺寸分别为m*n, n*p和p*q，且$m<n<p<q$，计算速度最快的是？
(AB)C <font face="黑体" color=green size=4>(1)</font>
AC(B)
A(BC)
所有效率都相同
3. 以下有关特征数据归一化的说法错误的是：
特征数据归一化加速梯度下降优化的速度
特征数据归一化有可能提高模型的精度
线性归一化适用于特征数值分化比较大的情况  <font face="黑体" color=green size=4>(1)</font>
概率模型不需要做归一化处理
4. 假定你在神经网络中的隐藏层中使用激活函数X，在特定神经元给定任意输入，你会得到输出[-0.0001]，X可能是一下哪一个？
ReLU
tanh  <font face="黑体" color=green size=4>(1)</font>
sigmoid
其他都不是
5. 下列哪些项所描述的相关技术是对的？
AdaGrad和L-BFGS使用的都是一阶差分
AdaGrad和L-BFGS使用的都是二阶差分
Adagrad使用的是一阶差分，L-BFGS使用的是二阶差分 <font face="黑体" color=green size=4>(1)</font>
Adagrad使用的是二阶差分，L-BFGS使用的是一阶差分
## 多选题
1. 关于主成分分析PCA说法正确的是：
我们必须在使用PCA前规范化数据   <font face="黑体" color=green size=4>(1)</font>
我们应该选择使得模型有最大variance的主成分  <font face="黑体" color=green size=4>(1)</font>
我们应该选择使得模型有最小variance的主成分
我们可以使用PCA在低维度上做数据可视化   <font face="黑体" color=green size=4>(1)</font>
2. 以下描述错误的是？
SVM是这样一个分类器，他寻找具有最小边缘的超平面，因此它也经常被称为最小边缘分类器（minimal margin classifier）  <font face="黑体" color=green size=4>(1)</font>
在聚类分析中，簇内的相似性越大，簇间的差别越大，聚类的效果越好
在决策树中，随着树中节点变得太大，即使模型的训练误差还在继续减低，但是检验误差开始增大，这是出现了模型拟合不足的问题  <font face="黑体" color=green size=4>(1)</font>
聚类分析可以看做是一种非监督的分类
3. 假设目标遍历的类别非常不平衡，即主要类别占据了训练数据的99%，现在你的模型在训练集上表现为99%的准确度，那么下面说法正确的是：
准确度并不适合衡量不平衡类别问题  <font face="黑体" color=green size=4>(1)</font>
准确度适合衡量不平衡类别问题
精确度和召回率适合于衡量不平衡类别问题  <font face="黑体" color=green size=4>(1)</font>
精确度和召回率不适合衡量不平衡类别问题
4. 神经网络训练过程中的哪些现象表明可能出现了梯度爆炸？
模型梯度快速变大  从<font face="黑体" color=green size=4>(1)</font>
模型权重变为NaN值   从<font face="黑体" color=green size=4>(1)</font>
每个节点和层的误差梯度值持续超过1.0
损失函数持续减小

## 填空题
1. 输入图片大小是200*200，依次经过一层卷积（kernel size 5*5,padding 1,stride 2),pooling(kernel size 3*3，padding 0，stride 1),又经过一层卷积（kernel size 3*3，padding 1,stride 1)，输出特征图大小为( )?

2. 在训练集标签为[0,0,0,1,1,1,1,1], 求信息熵的大小。
